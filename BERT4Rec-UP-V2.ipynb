{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149c4c1e-0441-416d-a0a4-160167e0d56c",
   "metadata": {},
   "source": [
    "# BERT4Rec UP - V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bbb2087-3a9f-42c3-ad30-794a9ccc411c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertModel, BertConfig\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure compatibility with Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "785a0a3c-1585-4095-a922-5ca1119fd11f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6040 users' movie interaction sequences.\n",
      "Train users: 4832, Test users: 1208\n",
      "Model initialized with vocab size 3953\n",
      "Epoch 1, Train Loss: 8.1018\n",
      "Epoch 2, Train Loss: 7.3164\n",
      "Epoch 3, Train Loss: 6.8969\n",
      "Epoch 4, Train Loss: 6.4634\n",
      "Epoch 5, Train Loss: 5.6522\n",
      "Epoch 6, Train Loss: 4.0472\n",
      "Epoch 7, Train Loss: 2.7484\n",
      "Epoch 8, Train Loss: 1.8936\n",
      "Epoch 9, Train Loss: 1.3391\n",
      "Epoch 10, Train Loss: 0.9695\n"
     ]
    }
   ],
   "source": [
    "# ✅ Load MovieLens-1M Data (Users, Ratings, Movies)\n",
    "def load_ratings(filepath=\"ml-1m/ratings.dat\"):\n",
    "    df = pd.read_csv(filepath, sep=\"::\", engine=\"python\",\n",
    "                     names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"],\n",
    "                     encoding=\"utf-8\")\n",
    "    df = df.sort_values(by=[\"userId\", \"timestamp\"])\n",
    "    user_movie_dict = df.groupby(\"userId\")[\"movieId\"].apply(list).to_dict()\n",
    "    return user_movie_dict, df\n",
    "\n",
    "def load_users(filepath=\"ml-1m/users.dat\"):\n",
    "    user_df = pd.read_csv(filepath, sep=\"::\", engine=\"python\",\n",
    "                           names=[\"userId\", \"gender\", \"age\", \"occupation\", \"zip-code\"],\n",
    "                           encoding=\"utf-8\")\n",
    "\n",
    "    gender_map = {\"M\": 0, \"F\": 1}\n",
    "    user_df[\"gender\"] = user_df[\"gender\"].map(gender_map)\n",
    "\n",
    "    age_groups = {1: 0, 18: 1, 25: 2, 35: 3, 45: 4, 50: 5, 56: 6}\n",
    "    user_df[\"age\"] = user_df[\"age\"].map(age_groups)\n",
    "\n",
    "    users_dict = user_df.set_index(\"userId\")[[\"gender\", \"age\", \"occupation\"]].to_dict(\"index\")\n",
    "    return users_dict\n",
    "\n",
    "def load_movies(filepath=\"ml-1m/movies.dat\"):\n",
    "    movies = pd.read_csv(filepath, sep=\"::\", engine=\"python\",\n",
    "                         names=[\"movieId\", \"title\", \"genres\"], encoding=\"latin-1\")\n",
    "\n",
    "    genre_list = [\n",
    "        \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\",\n",
    "        \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\",\n",
    "        \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "    ]\n",
    "    genre_dict = {genre: i + 1 for i, genre in enumerate(genre_list)}\n",
    "\n",
    "    movies[\"genre_vector\"] = movies[\"genres\"].apply(lambda x: [genre_dict[g] for g in x.split(\"|\") if g in genre_dict])\n",
    "    movie_dict = movies.set_index(\"movieId\")[\"genre_vector\"].to_dict()\n",
    "\n",
    "    return movie_dict, genre_dict\n",
    "\n",
    "# ✅ Load datasets\n",
    "user_movie_dict, ratings_df = load_ratings()\n",
    "users_dict = load_users()\n",
    "movie_dict, genre_dict = load_movies()\n",
    "\n",
    "print(f\"Loaded {len(user_movie_dict)} users' movie interaction sequences.\")\n",
    "\n",
    "# ✅ Strict Train/Test Split\n",
    "def split_train_test_strict(user_movie_dict, test_user_ratio=0.2, min_interactions=5):\n",
    "    users = list(user_movie_dict.keys())\n",
    "    np.random.shuffle(users)\n",
    "    split_idx = int(len(users) * (1 - test_user_ratio))\n",
    "    train_users = users[:split_idx]\n",
    "    test_users = users[split_idx:]\n",
    "\n",
    "    train_dict = {user: user_movie_dict[user] for user in train_users if len(user_movie_dict[user]) >= min_interactions}\n",
    "    test_dict = {user: user_movie_dict[user] for user in test_users if len(user_movie_dict[user]) >= min_interactions}\n",
    "\n",
    "    return train_dict, test_dict\n",
    "\n",
    "train_dict, test_dict = split_train_test_strict(user_movie_dict)\n",
    "print(f\"Train users: {len(train_dict)}, Test users: {len(test_dict)}\")\n",
    "\n",
    "\n",
    "# ✅ Negative Sampling\n",
    "def negative_sampling(movie_list, vocab_size, num_neg=2, max_len=30):\n",
    "    neg_samples = []\n",
    "    for _ in range(max_len):\n",
    "        neg = []\n",
    "        while len(neg) < num_neg:\n",
    "            sampled = np.random.randint(1, vocab_size)\n",
    "            if sampled not in movie_list:\n",
    "                neg.append(sampled)\n",
    "        neg_samples.append(neg)\n",
    "    return neg_samples  # Shape: (max_len, num_neg)\n",
    "\n",
    "# ✅ Define vocab_size\n",
    "vocab_size = max(max(seq) for seq in user_movie_dict.values()) + 1\n",
    "    \n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, user_movie_dict, users_dict, movie_dict, vocab_size, max_len=30, num_neg=2, max_genres=5):\n",
    "        self.users = list(user_movie_dict.keys())\n",
    "        self.sequences = [user_movie_dict[user] for user in self.users]\n",
    "        self.user_profiles = [users_dict[user] for user in self.users]\n",
    "        self.movie_dict = movie_dict\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_len = max_len\n",
    "        self.num_neg = num_neg\n",
    "        self.max_genres = max_genres\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        user_profile = self.user_profiles[idx]\n",
    "\n",
    "        gender, age, occupation = (\n",
    "            user_profile[\"gender\"], user_profile[\"age\"], user_profile[\"occupation\"]\n",
    "        )\n",
    "\n",
    "        input_ids = sequence[:self.max_len] + [0] * (self.max_len - len(sequence))\n",
    "        target_ids = input_ids[1:] + [0]\n",
    "        attention_mask = [1 if id != 0 else 0 for id in input_ids]\n",
    "\n",
    "        # ✅ 外部调用negative_sampling\n",
    "        neg_samples = negative_sampling(sequence, self.vocab_size, self.num_neg, self.max_len)\n",
    "        neg_samples = torch.tensor(neg_samples, dtype=torch.long)\n",
    "\n",
    "        genre_vectors = [self.movie_dict.get(movie, [0]) for movie in input_ids]\n",
    "        padded_genre_vectors = [g[:self.max_genres] + [0] * (self.max_genres - len(g)) for g in genre_vectors]\n",
    "        genre_tensor = torch.tensor(padded_genre_vectors, dtype=torch.long)\n",
    "\n",
    "        return (\n",
    "            torch.tensor(input_ids, dtype=torch.long),\n",
    "            torch.tensor(target_ids, dtype=torch.long),\n",
    "            neg_samples,\n",
    "            torch.tensor(attention_mask, dtype=torch.long),\n",
    "            torch.tensor(gender, dtype=torch.long),\n",
    "            torch.tensor(age, dtype=torch.long),\n",
    "            torch.tensor(occupation, dtype=torch.long),\n",
    "            genre_tensor\n",
    "        )\n",
    "\n",
    "# ✅ Update DataLoaders with `genre_ids`\n",
    "train_dataset = MovieDataset(train_dict, users_dict, movie_dict, vocab_size)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = MovieDataset(test_dict, users_dict, movie_dict, vocab_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "class BERT4Rec(nn.Module):\n",
    "    def __init__(self, vocab_size, num_genres, hidden_size=256, num_layers=4, num_heads=4, max_len=30, dropout_rate=0.2):\n",
    "        super(BERT4Rec, self).__init__()\n",
    "        config = BertConfig(\n",
    "            vocab_size=vocab_size, hidden_size=hidden_size, num_attention_heads=num_heads,\n",
    "            num_hidden_layers=num_layers, max_position_embeddings=max_len\n",
    "        )\n",
    "        self.bert = BertModel(config)\n",
    "        split_size = hidden_size // 3  # Adjusted due to removing activity embedding\n",
    "        self.gender_embedding = nn.Embedding(2, split_size)\n",
    "        self.age_embedding = nn.Embedding(7, split_size)\n",
    "        self.occupation_embedding = nn.Embedding(21, split_size)\n",
    "        self.genre_embedding = nn.Embedding(num_genres, hidden_size)\n",
    "        self.genre_fc = nn.Linear(hidden_size, hidden_size)\n",
    "        self.user_fc = nn.Linear(split_size * 3, hidden_size)\n",
    "        self.user_dropout = nn.Dropout(dropout_rate)\n",
    "        self.final_dropout = nn.Dropout(dropout_rate)\n",
    "        self.output_layer = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, gender, age, occupation, genre_ids):\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        causal_mask = torch.triu(torch.ones((seq_len, seq_len), dtype=torch.bool, device=input_ids.device), diagonal=1)\n",
    "        transformer_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_attention_mask=~causal_mask\n",
    "        ).last_hidden_state\n",
    "        genre_emb = self.genre_embedding(genre_ids).mean(dim=2)\n",
    "        genre_emb = self.genre_fc(genre_emb)\n",
    "        user_emb = self.user_fc(torch.cat([\n",
    "            self.gender_embedding(gender).unsqueeze(1).expand(-1, seq_len, -1),\n",
    "            self.age_embedding(age).unsqueeze(1).expand(-1, seq_len, -1),\n",
    "            self.occupation_embedding(occupation).unsqueeze(1).expand(-1, seq_len, -1)\n",
    "        ], dim=-1))\n",
    "        user_emb = self.user_dropout(user_emb)\n",
    "        output = transformer_output + user_emb + genre_emb\n",
    "        return self.output_layer(self.final_dropout(output))\n",
    "\n",
    "vocab_size = max(max(seq) for seq in user_movie_dict.values()) + 1\n",
    "model = BERT4Rec(vocab_size, len(genre_dict) + 1, dropout_rate=0.4).to(device)\n",
    "print(f\"Model initialized with vocab size {vocab_size}\")\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# ✅ Early Stopping Implementation\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.counter = 0\n",
    "\n",
    "    def step(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "# ✅ Updated Training Function\n",
    "def train_model(model, dataloader, epochs=10, lr=0.0001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    criterion_ce = nn.CrossEntropyLoss(ignore_index=0)  # Used for positive samples\n",
    "    criterion_bce = nn.BCEWithLogitsLoss()  # Used for negative sampling\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    early_stopping = EarlyStopping(patience=3)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, targets, neg_samples, attention_mask, gender, age, occupation, genre_ids in dataloader:\n",
    "            inputs, targets, neg_samples, attention_mask, gender, age, occupation, genre_ids = (\n",
    "                inputs.to(device), targets.to(device), neg_samples.to(device),\n",
    "                attention_mask.to(device), gender.to(device), age.to(device),\n",
    "                occupation.to(device),\n",
    "                genre_ids.to(device)\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, attention_mask, gender, age, occupation, genre_ids)  \n",
    "            # ✅ outputs.shape = [batch_size, seq_len, vocab_size]\n",
    "\n",
    "            # ✅ Compute Positive Sample Loss (CrossEntropy)\n",
    "            pos_loss = criterion_ce(outputs.view(-1, outputs.shape[-1]), targets.view(-1))  # Targets must be long integers\n",
    "\n",
    "            # ✅ Compute Negative Sample Loss (Binary Classification)\n",
    "            neg_logits = outputs.gather(2, neg_samples).squeeze(-1)  # Extract negative logits\n",
    "            neg_labels = torch.zeros_like(neg_logits)  # Label negative samples as \"0\"\n",
    "            neg_loss = criterion_bce(neg_logits, neg_labels.float())  # BCE expects float targets\n",
    "\n",
    "            # ✅ Compute Final Loss\n",
    "            loss = pos_loss + neg_loss.mean()\n",
    "\n",
    "            # ✅ Backpropagation\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # ✅ Learning Rate Scheduling\n",
    "        scheduler.step(total_loss)\n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "        # ✅ Early Stopping\n",
    "        if early_stopping.step(total_loss):\n",
    "            break\n",
    "\n",
    "# ✅ Train the Model\n",
    "train_model(model, train_dataloader, epochs=10, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91245a3f-032d-4b81-a2cd-6bac939a8313",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5159, Recall@10: 0.9222, NDCG@10: 0.9116\n"
     ]
    }
   ],
   "source": [
    "# Define Evaluation Function\n",
    "def evaluate_model(model, dataloader, k=10):\n",
    "    \"\"\"\n",
    "    Evaluate the BERT4Rec model on test data.\n",
    "\n",
    "    Args:\n",
    "        model: The trained BERT4Rec model.\n",
    "        dataloader: Test DataLoader.\n",
    "        k: Top-K predictions to consider for Recall and NDCG.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss, total_recall, total_ndcg = 0, 0, 0\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Unpack batch\n",
    "            inputs, targets, neg_samples, attention_mask, gender, age, occupation, genres = batch\n",
    "\n",
    "            # Move to device\n",
    "            inputs, targets, attention_mask = inputs.to(device), targets.to(device), attention_mask.to(device)\n",
    "            gender, age, occupation, genres = (\n",
    "                gender.to(device), age.to(device), occupation.to(device),\n",
    "                genres.to(device)\n",
    "            )\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs, attention_mask, gender, age, occupation, genres)\n",
    "            loss = criterion(outputs.view(-1, outputs.shape[-1]), targets.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Compute Recall@K & NDCG@K\n",
    "            _, top_k_predictions = torch.topk(outputs, k, dim=-1)  # Get top K movie predictions\n",
    "            recall = recall_at_k(top_k_predictions, targets, k)\n",
    "            ndcg = ndcg_at_k(top_k_predictions, targets, k)\n",
    "\n",
    "            total_recall += recall\n",
    "            total_ndcg += ndcg\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_recall = total_recall / len(dataloader)\n",
    "    avg_ndcg = total_ndcg / len(dataloader)\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Recall@{k}: {avg_recall:.4f}, NDCG@{k}: {avg_ndcg:.4f}\")\n",
    "\n",
    "# Compute Recall@K\n",
    "def recall_at_k(top_k_predictions, targets, k):\n",
    "    hits = (top_k_predictions == targets.unsqueeze(-1)).float()  # Check if target is in top K\n",
    "    recall = hits.sum(dim=-1).mean().item()  # Compute recall\n",
    "    return recall\n",
    "\n",
    "# Compute NDCG@K\n",
    "def ndcg_at_k(top_k_predictions, targets, k):\n",
    "    hits = (top_k_predictions == targets.unsqueeze(-1)).float()\n",
    "    log_positions = 1 / torch.log2(torch.arange(2, k + 2, device=targets.device).float())  # Discount factor\n",
    "    dcg = (hits * log_positions).sum(dim=-1).mean().item()\n",
    "    return dcg\n",
    "\n",
    "# Evaluate Model\n",
    "evaluate_model(model, test_dataloader, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d771b2-05ab-4525-926f-3b320ff5f55c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
